{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5edbe3-c07c-4476-9923-fcc7bec19847",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "Since the dawn of human life on the face of the earth, the global population has been booming. The population was estimated to be 1 billion people in the year 1800. The figure had increased to a new high of 6 billion humans by the turn of the twentieth century. Day in and day out, 227,000 people are being added to the world; it is projected that by the end of the 21st century, the world's population may exceed 11 billion.\n",
    "\n",
    "As per reports, as a consequence of the unsustainable increase in population and a lack of access to adequate health care, food, and shelter, the number of genetic disorder ailments have increased. Hereditary illnesses are becoming more common due to a lack of understanding about the need for genetic testing. Often kids die as a result of these illnesses, thus genetic testing during pregnancy is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ef8e9-251a-49a4-bc5e-8ee2cf6613e5",
   "metadata": {},
   "source": [
    "# Task\n",
    "You are hired as a Machine Learning Engineer from a government agency. You are given a dataset that contains medical information about children who have genetic disorders. Your task is to predict the following:\n",
    "\n",
    "Genetic disorder\n",
    "\n",
    "Disorder subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c479f5b-faa5-4984-90ac-dd9584fa0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling as pp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d337c3-f1b1-439f-af22-7479a082bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10\n",
    "ROOT_PATH ='processed_data'\n",
    "TRAIN_PATH = ROOT_PATH + '\\\\df_train_pr.csv'\n",
    "TEST_PATH = ROOT_PATH + \"\\\\df_test_pr.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75e749e-280b-460f-80a7-9567275b73a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18672 entries, 0 to 18671\n",
      "Data columns (total 28 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Patient_Age                   18672 non-null  int64  \n",
      " 1   Genes_Mother_Side             18672 non-null  object \n",
      " 2   Inherited_from_Father         18672 non-null  object \n",
      " 3   Maternal_Gene                 18672 non-null  object \n",
      " 4   Paternal_Gene                 18672 non-null  object \n",
      " 5   Blood_Cell_mcL                18672 non-null  float64\n",
      " 6   Mother_Age                    18672 non-null  int64  \n",
      " 7   Father_Age                    18672 non-null  int64  \n",
      " 8   Status                        18672 non-null  object \n",
      " 9   Respiratory_Rate_Breaths_Min  18672 non-null  object \n",
      " 10  Heart_Rates_Min               18672 non-null  object \n",
      " 11  Follow_Up                     18672 non-null  object \n",
      " 12  Gender                        18672 non-null  object \n",
      " 13  Birth_Asphyxia                18672 non-null  object \n",
      " 14  Autopsy_Birth_Defect          18672 non-null  object \n",
      " 15  Place_Birth                   18672 non-null  object \n",
      " 16  Folic_Acid                    18672 non-null  object \n",
      " 17  Maternal_Illness              18672 non-null  object \n",
      " 18  Radiation_Exposure            18672 non-null  object \n",
      " 19  Substance_Abuse               18672 non-null  object \n",
      " 20  Assisted_Conception           18672 non-null  object \n",
      " 21  History_Previous_Pregnancies  18672 non-null  object \n",
      " 22  Previous_Abortion             18672 non-null  int64  \n",
      " 23  Birth_Defects                 18672 non-null  object \n",
      " 24  White_Blood_Cell              18672 non-null  float64\n",
      " 25  Blood_Test_Result             18672 non-null  object \n",
      " 26  Genetic_Disorder              16987 non-null  object \n",
      " 27  Disorder_Subclass             18672 non-null  object \n",
      "dtypes: float64(2), int64(4), object(22)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "df_train = train_data.copy()\n",
    "df_test = test_data.copy()\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "042d0775-7c61-4373-acf0-fc129abb446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorial Variables\n",
      "['Genes_Mother_Side', 'Inherited_from_Father', 'Maternal_Gene', 'Paternal_Gene', 'Status', 'Respiratory_Rate_Breaths_Min', 'Heart_Rates_Min', 'Follow_Up', 'Gender', 'Birth_Asphyxia', 'Autopsy_Birth_Defect', 'Place_Birth', 'Folic_Acid', 'Maternal_Illness', 'Radiation_Exposure', 'Substance_Abuse', 'Assisted_Conception', 'History_Previous_Pregnancies', 'Previous_Abortion', 'Birth_Defects', 'Blood_Test_Result', 'Genetic_Disorder', 'Disorder_Subclass']\n",
      "Numeric Variables\n",
      "['Patient_Age', 'Blood_Cell_mcL', 'Mother_Age', 'Father_Age', 'White_Blood_Cell']\n"
     ]
    }
   ],
   "source": [
    "target_col = [\"Disorder_Subclass\"]\n",
    "cat_columns   = df_train.nunique()[df_train.nunique() < 12].keys().tolist()\n",
    "cat_columns   = [x for x in cat_columns ]\n",
    "print('Categorial Variables')\n",
    "print(cat_columns)\n",
    "#numerical columns\n",
    "num_columns   = [x for x in df_train.columns if x not in cat_columns + target_col]\n",
    "#Binary columns with 2 values\n",
    "print('Numeric Variables')\n",
    "print(num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db98c8d-9f41-4379-9fd2-879e35a31e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['Disorder_Subclass','Genetic_Disorder'],axis =1)\n",
    "y_train = df_train['Disorder_Subclass']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92aa0ffd-a1ef-40fe-801b-120169639d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = sorted(y_train.unique())\n",
    "\n",
    "dict1={}\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    dict1[labels[i]]=i\n",
    "    \n",
    "y=[]\n",
    "\n",
    "for i in y_train: \n",
    "    y.append(dict1[i])\n",
    "    \n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b33ce670-f50b-483b-93c6-88684260221e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 3, ..., 7, 6, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a4227e0-8512-4931-854b-b0c329884c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Alzheimer's\": 0,\n",
       " 'Cancer': 1,\n",
       " 'Cystic fibrosis': 2,\n",
       " 'Diabetes': 3,\n",
       " 'Hemochromatosis': 4,\n",
       " \"Leber's hereditary optic neuropathy\": 5,\n",
       " 'Leigh syndrome': 6,\n",
       " 'Mitochondrial myopathy': 7,\n",
       " 'Tay-Sachs': 8}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "232c8295-d183-475e-b0f2-69d235f95e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Data = pd.concat((X_train,df_test))\n",
    "all_Data_E = pd.get_dummies(all_Data, columns=cat_columns[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1dd926f-cb64-4d3c-90a6-2a38290e65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= pd.get_dummies(X_train, columns=cat_columns[:-2])\n",
    "X_test= pd.get_dummies(df_test, columns=cat_columns[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e406589e-2444-45d2-8c6c-d258aa661e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18672 entries, 0 to 18671\n",
      "Data columns (total 57 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   Patient_Age                                  18672 non-null  int64  \n",
      " 1   Blood_Cell_mcL                               18672 non-null  float64\n",
      " 2   Mother_Age                                   18672 non-null  int64  \n",
      " 3   Father_Age                                   18672 non-null  int64  \n",
      " 4   White_Blood_Cell                             18672 non-null  float64\n",
      " 5   Genes_Mother_Side_No                         18672 non-null  uint8  \n",
      " 6   Genes_Mother_Side_Yes                        18672 non-null  uint8  \n",
      " 7   Inherited_from_Father_No                     18672 non-null  uint8  \n",
      " 8   Inherited_from_Father_Yes                    18672 non-null  uint8  \n",
      " 9   Maternal_Gene_No                             18672 non-null  uint8  \n",
      " 10  Maternal_Gene_Yes                            18672 non-null  uint8  \n",
      " 11  Paternal_Gene_No                             18672 non-null  uint8  \n",
      " 12  Paternal_Gene_Yes                            18672 non-null  uint8  \n",
      " 13  Status_Alive                                 18672 non-null  uint8  \n",
      " 14  Status_Deceased                              18672 non-null  uint8  \n",
      " 15  Respiratory_Rate_Breaths_Min_Normal (30-60)  18672 non-null  uint8  \n",
      " 16  Respiratory_Rate_Breaths_Min_Tachypnea       18672 non-null  uint8  \n",
      " 17  Heart_Rates_Min_Normal                       18672 non-null  uint8  \n",
      " 18  Heart_Rates_Min_Tachycardia                  18672 non-null  uint8  \n",
      " 19  Follow_Up_High                               18672 non-null  uint8  \n",
      " 20  Follow_Up_Low                                18672 non-null  uint8  \n",
      " 21  Gender_Ambiguous                             18672 non-null  uint8  \n",
      " 22  Gender_Female                                18672 non-null  uint8  \n",
      " 23  Gender_Male                                  18672 non-null  uint8  \n",
      " 24  Birth_Asphyxia_No                            18672 non-null  uint8  \n",
      " 25  Birth_Asphyxia_No record                     18672 non-null  uint8  \n",
      " 26  Birth_Asphyxia_Yes                           18672 non-null  uint8  \n",
      " 27  Autopsy_Birth_Defect_No                      18672 non-null  uint8  \n",
      " 28  Autopsy_Birth_Defect_Not applicable          18672 non-null  uint8  \n",
      " 29  Autopsy_Birth_Defect_Yes                     18672 non-null  uint8  \n",
      " 30  Place_Birth_Home                             18672 non-null  uint8  \n",
      " 31  Place_Birth_Institute                        18672 non-null  uint8  \n",
      " 32  Folic_Acid_No                                18672 non-null  uint8  \n",
      " 33  Folic_Acid_Yes                               18672 non-null  uint8  \n",
      " 34  Maternal_Illness_No                          18672 non-null  uint8  \n",
      " 35  Maternal_Illness_Yes                         18672 non-null  uint8  \n",
      " 36  Radiation_Exposure_No                        18672 non-null  uint8  \n",
      " 37  Radiation_Exposure_Not applicable            18672 non-null  uint8  \n",
      " 38  Radiation_Exposure_Yes                       18672 non-null  uint8  \n",
      " 39  Substance_Abuse_No                           18672 non-null  uint8  \n",
      " 40  Substance_Abuse_Not applicable               18672 non-null  uint8  \n",
      " 41  Substance_Abuse_Yes                          18672 non-null  uint8  \n",
      " 42  Assisted_Conception_No                       18672 non-null  uint8  \n",
      " 43  Assisted_Conception_Yes                      18672 non-null  uint8  \n",
      " 44  History_Previous_Pregnancies_No              18672 non-null  uint8  \n",
      " 45  History_Previous_Pregnancies_Yes             18672 non-null  uint8  \n",
      " 46  Previous_Abortion_0                          18672 non-null  uint8  \n",
      " 47  Previous_Abortion_1                          18672 non-null  uint8  \n",
      " 48  Previous_Abortion_2                          18672 non-null  uint8  \n",
      " 49  Previous_Abortion_3                          18672 non-null  uint8  \n",
      " 50  Previous_Abortion_4                          18672 non-null  uint8  \n",
      " 51  Birth_Defects_Multiple                       18672 non-null  uint8  \n",
      " 52  Birth_Defects_Singular                       18672 non-null  uint8  \n",
      " 53  Blood_Test_Result_abnormal                   18672 non-null  uint8  \n",
      " 54  Blood_Test_Result_inconclusive               18672 non-null  uint8  \n",
      " 55  Blood_Test_Result_normal                     18672 non-null  uint8  \n",
      " 56  Blood_Test_Result_slightly abnormal          18672 non-null  uint8  \n",
      "dtypes: float64(2), int64(3), uint8(52)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b5b47f2-d0b7-413f-819f-e90d8111c622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#No hay valores distintos entre las columnas generadas\n",
    "#print(np.sum(X_train_E.columns!=X_test_E.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f75238d-cd9b-4247-8579-bd585ce2a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [{'name': 'logreg','label': 'Logistic Regression',\n",
    "           'classifier': LogisticRegression(random_state=88),\n",
    "           'grid': {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}},\n",
    "          \n",
    "          {'name': 'knn','label':'K Nearest Neighbors',\n",
    "           'classifier':KNeighborsClassifier(),\n",
    "           'grid': {\"n_neighbors\":np.arange(8)+1}},\n",
    "          \n",
    "          {'name': 'dsc','label': 'Descision Tree', \n",
    "           'classifier': DecisionTreeClassifier(random_state=88),\n",
    "           'grid': {\"max_depth\":np.arange(8)+1}},\n",
    "          \n",
    "          {'name': 'rf', 'label': 'Random Forest',\n",
    "           'classifier': RandomForestClassifier(random_state=88),\n",
    "           'grid': {'n_estimators': [100, 200, 500, 700],'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                    'max_depth' : [2,3,4,5,6,7,8],'criterion' :['gini', 'entropy']}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edca75ae-10b2-43c6-a8ff-302fb082abce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n",
      "Fitting 10 folds for each of 14 candidates, totalling 140 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0550b9a58094>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     results.append(model_selection(m['classifier'], \n\u001b[0m\u001b[0;32m     24\u001b[0m                                    \u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                                    \u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'grid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-0550b9a58094>\u001b[0m in \u001b[0;36mmodel_selection\u001b[1;34m(classifier, name, grid, X_train, y_train, scoring)\u001b[0m\n\u001b[0;32m      8\u001b[0m                                n_jobs = -1)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgridsearch_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mresults_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1459\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \"\"\"\n\u001b[1;32m-> 1461\u001b[1;33m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"saga\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"none\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    448\u001b[0m             \u001b[1;34m\"Solver %s supports only 'l2' or 'none' penalties, got %s penalty.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "\n",
    "def model_selection(classifier, name, grid, X_train, y_train, scoring):\n",
    "    \n",
    "    gridsearch_cv=GridSearchCV(classifier, \n",
    "                               grid,\n",
    "                               cv=10, \n",
    "                               scoring = scoring,\n",
    "                               verbose = 1,\n",
    "                               n_jobs = -1)\n",
    "    \n",
    "    gridsearch_cv.fit(X_train, y_train)\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    results_dict['classifier_name'] = name    \n",
    "    results_dict['classifier'] = gridsearch_cv.best_estimator_\n",
    "    results_dict['best_params'] = gridsearch_cv.best_params_\n",
    "    results_dict['ROC_AUC'] = gridsearch_cv.best_score_\n",
    "    \n",
    "    return(results_dict)\n",
    "results = []\n",
    "for m in models:    \n",
    "    print(m['name'])    \n",
    "    results.append(model_selection(m['classifier'], \n",
    "                                   m['name'],\n",
    "                                   m['grid'],\n",
    "                                   X_train, \n",
    "                                   y_train, \n",
    "                                   'roc_auc'))      \n",
    "    print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeff2507-521d-482f-bd52-ffef03f2bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "rand_forest_param = {\n",
    "    \"criterion\":['entropy'],\n",
    "    \"n_estimators\": [700],\n",
    "    \"max_features\": ['auto'],\n",
    "    \"max_depth\": [8],\n",
    "    'random_state':[88]\n",
    "}\n",
    "\n",
    "\n",
    "gs_rand_forest = GridSearchCV(rand_forest,\n",
    "                         rand_forest_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose = 1,\n",
    "                         n_jobs = -1)\n",
    "\n",
    "grids = {\"gs_rand_forest\": gs_rand_forest}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68d93983-ac4c-46d1-86de-1670ed3283a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "for nombre, grid_search in grids.items():\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48972bf4-346b-42a4-94d0-e3e095b85d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 3, ..., 7, 6, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ad941de-8f63-4060-82af-60858dcbceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26574586902690595\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 700, 'random_state': 88}\n",
      "RandomForestClassifier(criterion='entropy', max_depth=8, n_estimators=700,\n",
      "                       random_state=88)\n"
     ]
    }
   ],
   "source": [
    "print(gs_rand_forest.best_score_)\n",
    "print(gs_rand_forest.best_params_)\n",
    "print(gs_rand_forest.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "893ef4b1-7125-45ae-914e-a640bd5ac163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73dd5743-9763-46e7-b4a5-c4eebb3a6551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear algorithm was disabled.\n",
      "AutoML directory: AutoML_3\n",
      "The task is multiclass_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Baseline', 'Decision Tree', 'Random Forest', 'Xgboost', 'Neural Network']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 2 models\n",
      "1_Baseline logloss 1.841309 trained in 1.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 21:06:52,086 concurrent.futures ERROR exception calling callback for <Future at 0x254b586c4c0 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 404, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\multiprocessing\\queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\__init__.py\", line 3, in <module>\n",
      "    from supervised.automl import AutoML\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\automl.py\", line 3, in <module>\n",
      "    from supervised.base_automl import BaseAutoML\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\base_automl.py\", line 21, in <module>\n",
      "    from supervised.algorithms.registry import AlgorithmsRegistry\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\algorithms\\registry.py\", line 71, in <module>\n",
      "    import supervised.algorithms.xgboost\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\algorithms\\xgboost.py\", line 8, in <module>\n",
      "    import xgboost as xgb\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\__init__.py\", line 9, in <module>\n",
      "    from .core import DMatrix, DeviceQuantileDMatrix, Booster\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 195, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 178, in _load_lib\n",
      "    raise XGBoostError(\n",
      "xgboost.core.XGBoostError: XGBoost Library (xgboost.dll) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): ['[WinError 1455] El archivo de paginación es demasiado pequeño para completar la operación']\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 792, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Problem during computing permutation importance. Skipping ...\n",
      "2_DecisionTree logloss 1.793842 trained in 45.57 seconds\n",
      "* Step default_algorithms will try to check up to 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 21:07:54,085 concurrent.futures ERROR exception calling callback for <Future at 0x25499ef5850 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 404, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\multiprocessing\\queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\__init__.py\", line 3, in <module>\n",
      "    from supervised.automl import AutoML\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\automl.py\", line 3, in <module>\n",
      "    from supervised.base_automl import BaseAutoML\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\base_automl.py\", line 21, in <module>\n",
      "    from supervised.algorithms.registry import AlgorithmsRegistry\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\algorithms\\registry.py\", line 71, in <module>\n",
      "    import supervised.algorithms.xgboost\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\algorithms\\xgboost.py\", line 8, in <module>\n",
      "    import xgboost as xgb\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\__init__.py\", line 9, in <module>\n",
      "    from .core import DMatrix, DeviceQuantileDMatrix, Booster\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 195, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 178, in _load_lib\n",
      "    raise XGBoostError(\n",
      "xgboost.core.XGBoostError: XGBoost Library (xgboost.dll) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): ['[WinError 1455] El archivo de paginación es demasiado pequeño para completar la operación']\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 792, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Problem during computing permutation importance. Skipping ...\n",
      "3_Default_Xgboost logloss 1.82256 trained in 72.65 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 21:09:07,664 concurrent.futures ERROR exception calling callback for <Future at 0x254a9261910 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 404, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\multiprocessing\\queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\__init__.py\", line 3, in <module>\n",
      "    from supervised.automl import AutoML\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\automl.py\", line 3, in <module>\n",
      "    from supervised.base_automl import BaseAutoML\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\base_automl.py\", line 21, in <module>\n",
      "    from supervised.algorithms.registry import AlgorithmsRegistry\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\algorithms\\registry.py\", line 71, in <module>\n",
      "    import supervised.algorithms.xgboost\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\algorithms\\xgboost.py\", line 8, in <module>\n",
      "    import xgboost as xgb\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\__init__.py\", line 9, in <module>\n",
      "    from .core import DMatrix, DeviceQuantileDMatrix, Booster\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 195, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 178, in _load_lib\n",
      "    raise XGBoostError(\n",
      "xgboost.core.XGBoostError: XGBoost Library (xgboost.dll) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): ['[WinError 1455] El archivo de paginación es demasiado pequeño para completar la operación']\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 792, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Problem during computing permutation importance. Skipping ...\n",
      "4_Default_NeuralNetwork logloss 1.80776 trained in 20.8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 21:09:37,783 concurrent.futures ERROR exception calling callback for <Future at 0x25499f79460 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 404, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\multiprocessing\\queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\__init__.py\", line 3, in <module>\n",
      "    from supervised.automl import AutoML\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\automl.py\", line 3, in <module>\n",
      "    from supervised.base_automl import BaseAutoML\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\base_automl.py\", line 21, in <module>\n",
      "    from supervised.algorithms.registry import AlgorithmsRegistry\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\algorithms\\registry.py\", line 71, in <module>\n",
      "    import supervised.algorithms.xgboost\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\supervised\\algorithms\\xgboost.py\", line 8, in <module>\n",
      "    import xgboost as xgb\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\__init__.py\", line 9, in <module>\n",
      "    from .core import DMatrix, DeviceQuantileDMatrix, Booster\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 195, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 178, in _load_lib\n",
      "    raise XGBoostError(\n",
      "xgboost.core.XGBoostError: XGBoost Library (xgboost.dll) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): ['[WinError 1455] El archivo de paginación es demasiado pequeño para completar la operación']\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 792, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Problem during computing permutation importance. Skipping ...\n",
      "5_Default_RandomForest logloss 1.782773 trained in 65.84 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 1.782773 trained in 0.8 seconds\n",
      "AutoML fit time: 244.03 seconds\n",
      "AutoML best model: 5_Default_RandomForest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoML()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8e86002-1c10-4414-b577-0163847b49b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 5.846347472150814\n"
     ]
    }
   ],
   "source": [
    "# compute the MSE on test data\n",
    "predictions = automl.predict(X_train)\n",
    "print(\"Test MSE:\", mean_squared_error(y_train, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d1e94aa-83d5-4d0d-8ce5-f3ec659ee02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727077977720651"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.score(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
